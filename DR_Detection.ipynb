{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DR_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9-k7_1ET6jlr",
        "I8E-n2YCtxgA"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIfOIYwCqJQV"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJvcIlqSC7Vx"
      },
      "source": [
        "pip install keras-rectified-adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f7c9F8WdKSV"
      },
      "source": [
        "# import useful packages\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import dill\n",
        "import glob\n",
        "#from keras_radam import RAdam\n",
        "from random import shuffle\n",
        "from google.colab import drive\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, f1_score, accuracy_score, confusion_matrix\n",
        "from keras import layers, models, optimizers\n",
        "from keras.layers import GlobalAveragePooling2D,Dense,Dropout,Input,Conv2D,UpSampling2D,MaxPool2D,Flatten\n",
        "from imgaug import augmenters as iaa\n",
        "from keras.callbacks import ModelCheckpoint, Callback\n",
        "from math import ceil\n",
        "from keras.layers import GlobalAveragePooling2D,Dense,Dropout\n",
        "from keras.models import Model,load_model\n",
        "from keras.optimizers import Adam,SGD\n",
        "from keras.losses import huber_loss"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKpCTIsF27C7"
      },
      "source": [
        "Biuld connections with Google drive for data import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HTSbbyp3Hcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca46b58-d305-4e1c-81dc-bff152144df8"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O4g_iXrTL5K"
      },
      "source": [
        "## Image Generation & Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfBudzQWoF3n"
      },
      "source": [
        "### Keras biult-in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tnoi2U4Pgn7"
      },
      "source": [
        "Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POFf15TFUu_G"
      },
      "source": [
        "# import the file of labels\n",
        "labels = pd.read_csv('/content/gdrive/My Drive/aptos2019-blindness-detection/train.csv')\n",
        "# shuffle the data set\n",
        "labels = labels.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqGt9LXnkPND"
      },
      "source": [
        "# add file type to the column of file names\n",
        "labels['id_code'] = labels['id_code'].astype(str) + '.png'\n",
        "\n",
        "# encode the label column to a categorical variable\n",
        "labels['diagnosis'] = labels['diagnosis'].astype(str)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnacPQccVxku"
      },
      "source": [
        "# randomly split the labeled images into a training set and a test set in a ratio of 8:2\n",
        "train_and_val, test = train_test_split(labels, test_size=0.2,random_state=1002965829)\n",
        "# randomly subset 1/10 of the training set to form a validation set\n",
        "train, val = train_test_split(train_and_val, test_size=0.1,random_state=1002965829)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4si2Cn9R-ty"
      },
      "source": [
        "Generate image batches for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxQq4m9XSByh"
      },
      "source": [
        "# define a training image generator\n",
        "#train_gen = ImageDataGenerator(rescale = 1./255, \n",
        "                               #rotation_range = 10,\n",
        "                               #shear_range = 0.2, \n",
        "                               #zoom_range = 0.2,\n",
        "                               #horizontal_flip = True)\n",
        "\n",
        "train_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# define a test image generator\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# define a validation image generator\n",
        "val_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEgMPesxXU8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c1775d-7a66-4285-95d4-a987867569db"
      },
      "source": [
        "# define the image file path\n",
        "image_dir = '/content/gdrive/My Drive/aptos2019-blindness-detection/train_images'\n",
        "\n",
        "# generate training images\n",
        "train_images = train_gen.flow_from_dataframe(\n",
        "    dataframe = train, \n",
        "    directory = image_dir, \n",
        "    x_col='id_code', \n",
        "    y_col='diagnosis',\n",
        "    target_size=(350, 350),\n",
        "    batch_size=128, \n",
        "    class_mode='categorical')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2636 validated image filenames belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzw5EFFvf4YE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd33bb4-3c00-414b-9491-b44628a2571c"
      },
      "source": [
        "# generate test images\n",
        "test_images = test_gen.flow_from_dataframe(\n",
        "    dataframe = test, \n",
        "    directory = image_dir, \n",
        "    x_col='id_code', \n",
        "    y_col='diagnosis',\n",
        "    target_size=(350, 350),\n",
        "    batch_size = 64,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 733 validated image filenames belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwLXCSu5RAHe",
        "outputId": "caf6018e-da81-4683-f030-56671690ec30"
      },
      "source": [
        "# generate validation images\n",
        "val_images = val_gen.flow_from_dataframe(\n",
        "    dataframe = val, \n",
        "    directory = image_dir, \n",
        "    x_col='id_code', \n",
        "    y_col='diagnosis',\n",
        "    target_size=(350, 350),\n",
        "    batch_size = 64,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 293 validated image filenames belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEaTJnF9mbPa"
      },
      "source": [
        "# inspect the processed training data\n",
        "for batch, label in train_images:\n",
        "  for i in range(4):\n",
        "    plt.subplot(2,2,i+1)\n",
        "    plt.imshow(batch[i])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA547pN5KfM5"
      },
      "source": [
        "for batch in train_images[0]:\n",
        "  for i in range(10):\n",
        "    print(batch[i].shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-k7_1ET6jlr"
      },
      "source": [
        "### Customized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcV4FuoVPnV0"
      },
      "source": [
        "Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tp97KTBPpS1"
      },
      "source": [
        "# import the file of labels\n",
        "labels = pd.read_csv('/content/gdrive/My Drive/aptos2019-blindness-detection/train.csv')\n",
        "\n",
        "# add file type to the column of file names\n",
        "labels['id_code'] = labels['id_code'].astype(str) + '.png'\n",
        "\n",
        "# encode the label column to a categorical variable\n",
        "labels['diagnosis'] = labels['diagnosis'].astype(str)\n",
        "\n",
        "# randomly split the labeled images into a training set and a test set in a ratio of 8:2\n",
        "train_val, test = train_test_split(labels, test_size=0.2, random_state=1002965829)\n",
        "\n",
        "# randomly subset 1/10 of the training set to form a validation set\n",
        "train, val = train_test_split(train_val, test_size=0.1, random_state=1002965829)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EgdpFtzXcoP"
      },
      "source": [
        "Define a Customized Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2qdwoKM7E95"
      },
      "source": [
        "class data_generator(object):\n",
        "  \n",
        "  #####------------------------ Image Augmentation ----------------------#####\n",
        "  def augment(self, img, img_type, img_size):\n",
        "    # img: a single image\n",
        "    # image_type: train or val or test\n",
        "    # image_size: resized image size\n",
        "    #----------------------------------------------------------------------#\n",
        "    def clip_black_out(img):\n",
        "      m,n,k=img.shape\n",
        "      left_count=0\n",
        "      for j in range(n):\n",
        "        if (img[:,j]<=10).all():\n",
        "          left_count=left_count+1\n",
        "        else:\n",
        "          break\n",
        "      right_count=n\n",
        "      for j in range(n-1,0,-1):\n",
        "        if (img[:,j]<=10).all():\n",
        "          right_count=right_count-1\n",
        "        else:\n",
        "          break\n",
        "      upper_count=0\n",
        "      for j in range(m):\n",
        "        if (img[j,:]<=10).all():\n",
        "          upper_count=upper_count+1\n",
        "        else:\n",
        "          break\n",
        "      lower_count=m\n",
        "      for j in range(m-1,0,-1):\n",
        "        if (img[j,:]<=10).all():\n",
        "          lower_count=lower_count-1\n",
        "        else:\n",
        "          break\n",
        "      img=img[upper_count:lower_count,left_count:right_count]\n",
        "      return img\n",
        "    #----------------------------------------------------------------------#\n",
        "    def crop_image_from_gray(img,tol=7):\n",
        "      if img.ndim ==2:\n",
        "        mask = img>tol\n",
        "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "      elif img.ndim==3:\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        mask = gray_img>tol\n",
        "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
        "          return img # return original image\n",
        "        else:\n",
        "          img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "          img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "          img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "          img = np.stack([img1,img2,img3],axis=-1)\n",
        "        return img\n",
        "\n",
        "    def load_ben_color(img, sigmaX=40):\n",
        "      img = crop_image_from_gray(img)\n",
        "      img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "      return img\n",
        "    #----------------------------------------------------------------------#\n",
        "    if img_type == 'validation' or 'test':\n",
        "      img = load_ben_color(clip_black_out(img))\n",
        "      img = cv2.resize(img,(img_size, img_size))\n",
        "      return img\n",
        "    if img_type == 'training':\n",
        "      augmenter = iaa.Sequential(\n",
        "          [iaa.OneOf([iaa.Affine(rotate=0), iaa.Affine(rotate=5), iaa.Affine(rotate=10)]),\n",
        "           iaa.OneOf([iaa.Fliplr(0.5)])], \n",
        "           random_order=True)\n",
        "      img = augmenter.augment_image(load_ben_color(clip_black_out(img)))\n",
        "      img = cv2.resize(img,(img_size,img_size))\n",
        "      return img\n",
        "\n",
        "  #####------------------------ Image Import ----------------------#####\n",
        "  def load_image(self, path, img_type, img_size, augment=False):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    if augment:\n",
        "      return self.augment(img, img_type, img_size)/255.\n",
        "    else:\n",
        "      img=cv2.resize(img,(img_size, img_size))\n",
        "      return img/255.\n",
        "  \n",
        "  ######------------------------ Image Batch Mix-up ----------------------#####\n",
        "  def mix_up(self, x_batch, y_batch):\n",
        "    x_batch= np.array(x_batch, np.float32)\n",
        "    y_batch=np.array(y_batch, np.float32)\n",
        "    lam = np.random.beta(0.2, 0.4)\n",
        "    ori_index = np.arange(int(len(x_batch))).astype('int')\n",
        "    index_array = np.arange(int(len(x_batch))).astype('int')\n",
        "    np.random.shuffle(index_array) \n",
        "     \n",
        "    mixed_x = lam * x_batch[ori_index] + (1 - lam) * x_batch[index_array]\n",
        "    mixed_y = lam * y_batch[ori_index] + (1 - lam) * y_batch[index_array]\n",
        "    return mixed_x, mixed_y\n",
        "  \n",
        "  ######--------------------------- Batch Generator -------------------------#####\n",
        "  def create_batch(self, my_dir, pred_mod, data_info, data_type, batch_size, resize_to, \n",
        "                   augment=False, mix=False):\n",
        "    # my_dir: the base directory to the image files\n",
        "    # pred_mod: treat the labels as classfification or regression\n",
        "    # data_info: paths to each image and their labels\n",
        "    # data_type: train, val, or test\n",
        "    # batch_size: batch_size\n",
        "    # resize_to: rescaled size\n",
        "    # augment: whether do image augmentations \n",
        "    # mix: whether mix up each batch\n",
        "    assert pred_mod in ['cls', 'reg'], 'incorrect prediction mode inputted'\n",
        "    assert data_type in ['training', 'validation', 'test'], 'incorrect data type inputted'\n",
        "\n",
        "    while True:\n",
        "      if data_type == 'training':\n",
        "        data_info = data_info.sample(frac=1).reset_index(drop=True)\n",
        "      for start in range(0, len(data_info), batch_size):\n",
        "        end = min(start + batch_size, len(data_info))\n",
        "        batch_info = data_info.iloc[start:end]\n",
        "        batch_images=[]\n",
        "        batch_labels = []\n",
        "        for i in range(len(batch_info)):\n",
        "          image = self.load_image(os.path.join(my_dir,batch_info.iloc[i]['id_code']), \n",
        "              data_type, \n",
        "              resize_to, \n",
        "              augment)\n",
        "          batch_images.append(image)\n",
        "          if pred_mod == 'cls':\n",
        "            num_classes = len(pd.unique(data_info.iloc[:,1]))\n",
        "            one_hot = np.zeros(num_classes)\n",
        "            one_hot[int(batch_info.iloc[i,1:].values)] = 1\n",
        "            batch_labels.append(one_hot)\n",
        "          else:\n",
        "            batch_labels.append(np.array(batch_info.iloc[i,1:].values, np.float32)/4.)\n",
        "        if mix:\n",
        "          batch_images, batch_labels = self.mix_up(batch_images, batch_labels)\n",
        "        yield np.array(batch_images), np.array(batch_labels, np.float32)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdRNENAcNzZ7"
      },
      "source": [
        "# define an image generator\n",
        "image_gen = data_generator()\n",
        "\n",
        "# generate training data\n",
        "train_images = image_gen.create_batch(\n",
        "    my_dir = '/content/gdrive/My Drive/aptos2019-blindness-detection/train_images', \n",
        "    pred_mod = 'cls',\n",
        "    data_info = train,\n",
        "    data_type = 'training',\n",
        "    batch_size = 128,\n",
        "    resize_to = 350,\n",
        "    augment = False,\n",
        "    mix = False)\n",
        "\n",
        "# generate validation data\n",
        "val_images = image_gen.create_batch(\n",
        "    my_dir = '/content/gdrive/My Drive/aptos2019-blindness-detection/train_images', \n",
        "    pred_mod = 'cls',\n",
        "    data_info = val,\n",
        "    data_type = 'validation',\n",
        "    batch_size = 64,\n",
        "    resize_to = 350,\n",
        "    augment = False,\n",
        "    mix = False)\n",
        "\n",
        "# generate test data\n",
        "test_images = image_gen.create_batch(\n",
        "    my_dir = '/content/gdrive/My Drive/aptos2019-blindness-detection/train_images', \n",
        "    pred_mod = 'cls',\n",
        "    data_info = test,\n",
        "    data_type = 'test',\n",
        "    batch_size = 64,\n",
        "    resize_to = 350,\n",
        "    augment = False,\n",
        "    mix = False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGGHIz12kAkh"
      },
      "source": [
        "# inspect the image processing\n",
        "for batch, label in train_images:\n",
        "  for i in range(4):\n",
        "    plt.subplot(2,2,i+1)\n",
        "    plt.imshow(batch[i])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee6J1bxxTmpa"
      },
      "source": [
        "## Training Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SemYO_5Y6-pH"
      },
      "source": [
        "### Focal loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT0eFWSc8bLA"
      },
      "source": [
        "Binary Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OHJUGiv7DJG"
      },
      "source": [
        "def binary_focal_loss(gamma=2., alpha=.25):\n",
        "    \"\"\"\n",
        "    Binary form of focal loss.\n",
        "      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
        "      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
        "    References:\n",
        "        https://arxiv.org/pdf/1708.02002.pdf\n",
        "    Usage:\n",
        "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
        "    \"\"\"\n",
        "\n",
        "    def binary_focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        :param y_true: A tensor of the same shape as `y_pred`\n",
        "        :param y_pred:  A tensor resulting from a sigmoid\n",
        "        :return: Output tensor.\n",
        "        \"\"\"\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
        "        epsilon = K.epsilon()\n",
        "        # Add the epsilon to prediction value\n",
        "        # y_pred = y_pred + epsilon\n",
        "        # Clip the prediciton value\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "        # Calculate p_t\n",
        "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        # Calculate alpha_t\n",
        "        alpha_factor = K.ones_like(y_true) * alpha\n",
        "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
        "        # Calculate cross entropy\n",
        "        cross_entropy = -K.log(p_t)\n",
        "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
        "        # Calculate focal loss\n",
        "        loss = weight * cross_entropy\n",
        "        # Sum the losses in mini_batch\n",
        "        loss = K.mean(K.sum(loss, axis=1))\n",
        "        return loss\n",
        "\n",
        "    return binary_focal_loss_fixed"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I9DW1Xp8hl6"
      },
      "source": [
        "Multi-class Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ6Z-ZMh8nyr"
      },
      "source": [
        "def categorical_focal_loss(alpha=[[0.25, 0.25, 0.25, 0.25, 0.25]], gamma=2.):\n",
        "    \"\"\"\n",
        "    Softmax version of focal loss.\n",
        "    When there is a skew between different categories/labels in your data set, you can try to apply this function as a\n",
        "    loss.\n",
        "           m\n",
        "      FL = âˆ‘  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
        "          c=1\n",
        "      where m = number of classes, c = class and o = observation\n",
        "    Parameters:\n",
        "      alpha -- the same as weighing factor in balanced cross entropy. Alpha is used to specify the weight of different\n",
        "      categories/labels, the size of the array needs to be consistent with the number of classes.\n",
        "      gamma -- focusing parameter for modulating factor (1-p)\n",
        "    Default value:\n",
        "      gamma -- 2.0 as mentioned in the paper\n",
        "      alpha -- 0.25 as mentioned in the paper\n",
        "    References:\n",
        "        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
        "        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
        "    Usage:\n",
        "     model.compile(loss=[categorical_focal_loss(alpha=[[.25, .25, .25]], gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
        "    \"\"\"\n",
        "\n",
        "    alpha = np.array(alpha, dtype=np.float32)\n",
        "\n",
        "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        :param y_true: A tensor of the same shape as `y_pred`\n",
        "        :param y_pred: A tensor resulting from a softmax\n",
        "        :return: Output tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        # Clip the prediction value to prevent NaN's and Inf's\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        # Calculate Cross Entropy\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "\n",
        "        # Calculate Focal Loss\n",
        "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
        "\n",
        "        # Compute mean loss in mini_batch\n",
        "        return K.mean(K.sum(loss, axis=-1))\n",
        "\n",
        "    return categorical_focal_loss_fixed"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqnF59NGE5Cw"
      },
      "source": [
        "### Huber loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8U65RamFAn7"
      },
      "source": [
        "def smooth_L1_loss(y_true, y_pred):\n",
        "    return huber_loss(y_true, y_pred)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnupI9cT__fw"
      },
      "source": [
        "### Cosine annealing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SEyTnBtADQJ"
      },
      "source": [
        "def get_1cycle_schedule(lr_max=1e-3, n_data_points=8000, epochs=200, batch_size=40, verbose=0):          \n",
        "    \"\"\"\n",
        "    Creates a look-up table of learning rates for 1cycle schedule with cosine annealing\n",
        "    See @sgugger's & @jeremyhoward's code in fastai library: https://github.com/fastai/fastai/blob/master/fastai/train.py\n",
        "    Wrote this to use with my Keras and (non-fastai-)PyTorch codes.\n",
        "    Note that in Keras, the LearningRateScheduler callback (https://keras.io/callbacks/#learningratescheduler) only operates once per epoch, not per batch\n",
        "      So see below for Keras callback\n",
        "\n",
        "    Keyword arguments:\n",
        "    lr_max            chosen by user after lr_finder\n",
        "    n_data_points     data points per epoch (e.g. size of training set)\n",
        "    epochs            number of epochs\n",
        "    batch_size        batch size\n",
        "    Output:  \n",
        "    lrs               look-up table of LR's, with length equal to total # of iterations\n",
        "    Then you can use this in your PyTorch code by counting iteration number and setting\n",
        "          optimizer.param_groups[0]['lr'] = lrs[iter_count]\n",
        "    \"\"\"\n",
        "    if verbose > 0:\n",
        "        print(\"Setting up 1Cycle LR schedule...\")\n",
        "    pct_start, div_factor = 0.3, 25.        # @sgugger's parameters in fastai code\n",
        "    lr_start = lr_max/div_factor\n",
        "    lr_end = lr_start/1e4\n",
        "    n_iter = ((n_data_points -1)* epochs // batch_size) + 1    # number of iterations\n",
        "    a1 = int(n_iter * pct_start)\n",
        "    a2 = n_iter - a1\n",
        "\n",
        "    # make look-up table\n",
        "    lrs_first = np.linspace(lr_start, lr_max, a1)            # linear growth\n",
        "    lrs_second = (lr_max-lr_end)*(1+np.cos(np.linspace(0,np.pi,a2)))/2 + lr_end  # cosine annealing\n",
        "    lrs = np.concatenate((lrs_first, lrs_second))\n",
        "    return lrs\n",
        "\n",
        "\n",
        "class OneCycleScheduler(Callback):\n",
        "    \"\"\"My modification of Keras' Learning rate scheduler to do 1Cycle learning\n",
        "       which increments per BATCH, not per epoch\n",
        "    Keyword arguments\n",
        "        **kwargs:  keyword arguments to pass to get_1cycle_schedule()\n",
        "        Also, verbose: int. 0: quiet, 1: update messages.\n",
        "\n",
        "    Sample usage (from my train.py):\n",
        "        lrsched = OneCycleScheduler(lr_max=1e-4, n_data_points=X_train.shape[0],\n",
        "        epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(OneCycleScheduler, self).__init__()\n",
        "        self.verbose = kwargs.get('verbose', 0)\n",
        "        self.lrs = get_1cycle_schedule(**kwargs)\n",
        "        self.iteration = 0\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        lr = self.lrs[self.iteration]\n",
        "        K.set_value(self.model.optimizer.lr, lr)         # here's where the assignment takes place\n",
        "        '''\n",
        "        if self.verbose > 3:\n",
        "            print('\\nIteration %06d: OneCycleScheduler setting learning '\n",
        "                  'rate to %s.' % (self.iteration, lr))\n",
        "        '''\n",
        "        self.iteration += 1\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):  # this is unchanged from Keras LearningRateScheduler\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
        "        # self.iteration = 0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NffwgjaZUqtb"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVIJLhJ3pF_Z"
      },
      "source": [
        "### V1 for classificastion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV3PKT-SrPik"
      },
      "source": [
        "# construct a CNN\n",
        "model_v1 = models.Sequential()\n",
        "\n",
        "model_v1.add(layers.Conv2D(128, (5, 5), activation = 'relu',\n",
        "                                 input_shape = (350, 350, 3))) \n",
        "model_v1.add(layers.MaxPooling2D((2, 2))) \n",
        "model_v1.add(layers.Conv2D(64, (3, 3), activation = 'relu')) \n",
        "model_v1.add(layers.MaxPooling2D((2, 2)))\n",
        "model_v1.add(layers.Conv2D(64, (3, 3), activation = 'relu')) \n",
        "model_v1.add(layers.MaxPooling2D((2, 2)))\n",
        "model_v1.add(layers.Conv2D(64, (3, 3), activation = 'relu')) \n",
        "model_v1.add(layers.MaxPooling2D((2, 2)))\n",
        "model_v1.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model_v1.add(layers.MaxPooling2D((2, 2))) \n",
        "model_v1.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model_v1.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model_v1.add(layers.Conv2D(64, (3, 3), activation = 'relu'))  \n",
        "model_v1.add(layers.Flatten())\n",
        "model_v1.add(layers.Dense(128, activation = 'relu'))\n",
        "model_v1.add(layers.Dense(64, activation = 'relu'))\n",
        "model_v1.add(layers.Dense(5, activation = 'softmax'))\n",
        "\n",
        "model_v1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfFEujZ01IEI"
      },
      "source": [
        "model_v1.compile(loss = [categorical_focal_loss()],\n",
        "              optimizer = 'adam', \n",
        "              metrics=['acc'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UAeyS5a1MZX"
      },
      "source": [
        "num_epochs = 8\n",
        "train_steps = ceil(len(train)/128)\n",
        "val_steps = ceil(len(val)/64)\n",
        "\n",
        "# define the check point\n",
        "filepath = '/content/gdrive/My Drive/aptos2019-blindness-detection/model_v1'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, \n",
        "                             save_best_only = True, mode = 'max', save_weights_only = False)\n",
        "\n",
        "# define the cosine leraning rate\n",
        "lrsched = OneCycleScheduler(lr_max = 0.001, n_data_points = len(train),\n",
        "        epochs = num_epochs, batch_size = 128, verbose = 0)\n",
        "\n",
        "# train the model\n",
        "model_v1.fit_generator(\n",
        "    train_images,\n",
        "    steps_per_epoch = train_steps,\n",
        "    validation_data = val_images,\n",
        "    validation_steps = val_steps,\n",
        "    epochs = num_epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [checkpoint, lrsched])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPgnfhEYF4cP"
      },
      "source": [
        "# load the model back\n",
        "model_v1 = models.load_model('/content/gdrive/My Drive/aptos2019-blindness-detection/model_v1', compile = False)\n",
        "model_v1.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yKdLg7v5fi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e382c6fe-a916-40b2-ca6b-5558e68a30b6"
      },
      "source": [
        "# generate the network's outputs for the test set\n",
        "test_steps = ceil(len(test)/64)\n",
        "predictions = model_v1.predict_generator(test_images, steps = test_steps)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1976: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6B-k-zI907M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d29da1-0b14-4863-9a40-102af1712ea0"
      },
      "source": [
        "# convert the outputs to certain categories\n",
        "pred_labels = predictions.argmax(axis = 1).astype(str)\n",
        "true_labels = test['diagnosis'].to_numpy()\n",
        "\n",
        "# compute performance metrics\n",
        "weighted_f1 = round(f1_score(true_labels, pred_labels, average = 'weighted'), 4) \n",
        "accuracy = round(accuracy_score(true_labels, pred_labels), 4) \n",
        "kappa = round(cohen_kappa_score(true_labels, pred_labels), 4)\n",
        "\n",
        "# display the metrics\n",
        "print(\"Accuracy: {}\".format(accuracy) + '\\n'\n",
        "      + \"Weigjted F1: {}\".format(weighted_f1) + '\\n'\n",
        "      + \"Cohen's Kappa: {}\".format(kappa))\n",
        "\n",
        "# display the confusion matrix\n",
        "confusion_matrix(true_labels, pred_labels)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3752\n",
            "Weigjted F1: 0.3499\n",
            "Cohen's Kappa: -0.0027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[191,  32, 134,   5,   0],\n",
              "       [ 38,   4,  25,   2,   0],\n",
              "       [112,  12,  78,   0,   0],\n",
              "       [ 18,   5,   9,   2,   0],\n",
              "       [ 37,   3,  26,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlF_9yMuLtEB"
      },
      "source": [
        "### V2 for regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2_XdUojL1jF"
      },
      "source": [
        "model_v2 = models.Sequential()\n",
        "\n",
        "model_v2.add(layers.Conv2D(128, (5, 5), activation = 'relu',\n",
        "                                 input_shape = (350, 350, 3))) # output shape: (254, 254, 16)\n",
        "model_v2.add(layers.MaxPooling2D((2, 2))) # output shape: (127, 127, 16)\n",
        "model_v2.add(layers.Conv2D(64, (3, 3), activation = 'relu')) # output shape: (125, 125, 32)\n",
        "model_v2.add(layers.MaxPooling2D((2, 2))) # output shape: (62, 62, 32)\n",
        "model_v2.add(layers.Conv2D(64, (3, 3), activation = 'relu')) # output shape: (60, 60, 64)\n",
        "model_v2.add(layers.MaxPooling2D((2, 2))) # output shape: (30, 30, 64)\n",
        "model_v2.add(layers.Conv2D(64, (3, 3), activation = 'relu')) # output shape: (60, 60, 64)\n",
        "model_v2.add(layers.MaxPooling2D((2, 2))) # output shape: (30, 30, 64)\n",
        "model_v2.add(layers.Conv2D(64, (3, 3), activation = 'relu')) # output shape: (60, 60, 64)\n",
        "model_v2.add(layers.MaxPooling2D((2, 2)))\n",
        "model_v2.add(layers.Conv2D(64, (3, 3), activation = 'relu')) # output shape: (60, 60, 64)\n",
        "model_v2.add(layers.Flatten())\n",
        "model_v2.add(layers.Dense(64, activation = 'relu'))\n",
        "model_v2.add(layers.Dense(32, activation = 'relu'))\n",
        "model_v2.add(layers.Dense(1, activation = 'linear'))\n",
        "model_v2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSIZdTQHM_MD"
      },
      "source": [
        "model_v2.compile(loss = [smooth_L1_loss],\n",
        "              optimizer = 'adam', \n",
        "              metrics=['mae'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu1wdy_dNCeZ"
      },
      "source": [
        "num_epochs = 10\n",
        "train_steps = ceil(len(train)/128)\n",
        "val_steps = ceil(len(val)/64)\n",
        "\n",
        "# define the check point\n",
        "filepath = '/content/gdrive/My Drive/aptos2019-blindness-detection/model_v2'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \n",
        "                             save_best_only=True, mode='auto', save_weights_only = False)\n",
        "\n",
        "# define the cosine leraning rate\n",
        "lrsched = OneCycleScheduler(lr_max = 1e-3, n_data_points = len(train),\n",
        "        epochs = num_epochs, batch_size = 128, verbose = 0)\n",
        "\n",
        "# train the model\n",
        "model_v2.fit_generator(\n",
        "    train_images,\n",
        "    steps_per_epoch = train_steps,\n",
        "    validation_data = val_images,\n",
        "    validation_steps = val_steps,\n",
        "    epochs = num_epochs,\n",
        "    verbose=1,\n",
        "    callbacks = [checkpoint, lrsched])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSkrWJb8yyoV"
      },
      "source": [
        "# load the model back\n",
        "model_v2 = models.load_model('/content/gdrive/My Drive/aptos2019-blindness-detection/model_v2', compile = False)\n",
        "model_v2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmCWrS4SPnx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e01c64b-3d80-4c20-f274-d8d54b1efa36"
      },
      "source": [
        "# generate predicted labels for the test set\n",
        "test_steps = ceil(len(test)/64)\n",
        "predictions = model_v2.predict_generator(test_images,steps = test_steps)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1976: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CSf9oKsYacZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8632ddb8-7c08-4606-9cff-4b55463262b3"
      },
      "source": [
        "pred = predictions * 4\n",
        "\n",
        "# map the numeric results to the corresponding classes\n",
        "for i in range(pred.shape[0]):\n",
        "    if(pred[i]<=0.5):\n",
        "        pred[i]=0\n",
        "    elif(pred[i]>0.5 and pred[i]<=1.2):\n",
        "        pred[i]=1\n",
        "    elif(pred[i]>1.2 and pred[i]<=2.5):\n",
        "        pred[i]=2\n",
        "    elif(pred[i]>2.5 and pred[i]<=3.5):\n",
        "        pred[i]=3\n",
        "    else:\n",
        "        pred[i]=4\n",
        "\n",
        "pred_labels = pred\n",
        "true_labels = test['diagnosis'].to_numpy().astype('int')\n",
        "\n",
        "# compute performance metrics\n",
        "weighted_f1 = round(f1_score(true_labels, pred_labels, average = 'weighted'), 4) # 0.3139\n",
        "accuracy = round(accuracy_score(true_labels, pred_labels), 4) # 0.3138\n",
        "kappa = round(cohen_kappa_score(true_labels, pred_labels), 4) # 0.0073\n",
        "\n",
        "# display the metrics\n",
        "print(\"Accuracy: {}\".format(accuracy) + '\\n'\n",
        "      + \"Weigjted F1: {}\".format(weighted_f1) + '\\n'\n",
        "      + \"Cohen's Kappa: {}\".format(kappa))\n",
        "\n",
        "# display the confusion matrix\n",
        "confusion_matrix(true_labels, pred_labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6467\n",
            "Weigjted F1: 0.619\n",
            "Cohen's Kappa: 0.4594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[297,  49,  16,   0,   0],\n",
              "       [  7,   2,  60,   0,   0],\n",
              "       [  4,  20, 174,   4,   0],\n",
              "       [  0,   2,  31,   1,   0],\n",
              "       [  3,   6,  55,   2,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6znjDRr0-zB3"
      },
      "source": [
        "## Auto-Encoder Pretrained CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWocYbTP-tGT"
      },
      "source": [
        "# import the file of labels\n",
        "labels = pd.read_csv('/content/gdrive/My Drive/aptos2019-blindness-detection/train.csv')\n",
        "\n",
        "# add file type to the column of file names\n",
        "labels['id_code'] = labels['id_code'].astype(str) + '.png'\n",
        "\n",
        "# encode the label column to a categorical variable\n",
        "labels['diagnosis'] = labels['diagnosis'].astype(str)\n",
        "\n",
        "# randomly split the labeled images into a training set and a test set in a ratio of 8:2\n",
        "train_val, test = train_test_split(labels, test_size=0.2, random_state=1002965829)\n",
        "\n",
        "# randomly subset 1/10 of the training set to form a validation set\n",
        "train, val = train_test_split(train_val, test_size=0.1, random_state=1002965829)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRLBvoZq7ev5"
      },
      "source": [
        "Combine the labeled data and unlabeled data into one dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91YNjvpN-xZw"
      },
      "source": [
        "# manipulate the labeled data info\n",
        "train['filename']='/content/gdrive/My Drive/aptos2019-blindness-detection/train_images'\n",
        "train.drop(columns=['diagnosis'],inplace=True)\n",
        "\n",
        "# create a dataframe to contain the file paths of the unlabeled images\n",
        "test_paths=glob.glob('/content/gdrive/My Drive/aptos2019-blindness-detection/test_images/*png')\n",
        "def transfrom_name(file_paths):\n",
        "    return os.path.split(file_paths)[1]\n",
        "def transfrom_file_name(file_paths):\n",
        "    return os.path.split(file_paths)[0]\n",
        "train_1 = pd.DataFrame({'id_code':test_paths,'filename':test_paths})\n",
        "train_1['filename']=train_1['filename'].map(transfrom_file_name)\n",
        "train_1['id_code']=train_1['id_code'].map(transfrom_name)\n",
        "\n",
        "# shuffle the combined data\n",
        "all_df = pd.concat([train,train_1])\n",
        "all_df = all_df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOTs5e677n3a"
      },
      "source": [
        "Define a simple image generator for the auto-encoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM0naJ5JB2W8"
      },
      "source": [
        "class my_gen(object):\n",
        "    def __init__(self, df, batchSize,image_size):\n",
        "        self.df=df\n",
        "        self.batchSize=batchSize\n",
        "        self.numImage=self.df.shape[0]\n",
        "        self.image_size=image_size\n",
        "        \n",
        "    def generator(self, passes=np.inf):\n",
        "        epochs = 0\n",
        "        while epochs <passes:\n",
        "            for i in range(0, self.numImage, self.batchSize):\n",
        "                paths_name=self.df.iloc[i:i+self.batchSize]['id_code'].tolist()\n",
        "                paths_filename=self.df.iloc[i:i+self.batchSize]['filename'].tolist()\n",
        "                \n",
        "                data=np.zeros((len(paths_name),self.image_size,self.image_size,3))\n",
        "                for j,name in enumerate(paths_name):\n",
        "                    img=cv2.imread(os.path.join(paths_filename[j],name))\n",
        "                    img=cv2.resize(img,(self.image_size,self.image_size))\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img=self.load_ben_color(img)\n",
        "                    img=img/255.0\n",
        "                    data[j]=img\n",
        "                yield (data,data)\n",
        "        epochs=epochs+1\n",
        "\n",
        "    def load_ben_color(self,image, sigmaX=20):\n",
        "        image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
        "\n",
        "        return image"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mLFSAfP7zif"
      },
      "source": [
        "Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0phThQoPgBL"
      },
      "source": [
        "batch_size=128\n",
        "image_size=384\n",
        "train_gen=my_gen(all_df,batch_size,image_size)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX1eEyeD741O"
      },
      "source": [
        "# define the architecture of the encoder/decoder model\n",
        "inputs=Input(shape=(image_size,image_size,3))\n",
        "x=Conv2D(filters=128,kernel_size=5,padding='same',strides=1,activation='relu')(inputs)\n",
        "x=MaxPool2D()(x)\n",
        "x=Conv2D(filters=64,kernel_size=5,padding='same',strides=1,activation='relu')(x)\n",
        "x=MaxPool2D()(x)\n",
        "x=Conv2D(filters=64,kernel_size=5,padding='same',strides=1,activation='relu')(x)\n",
        "x=MaxPool2D()(x)\n",
        "x=Conv2D(filters=32,kernel_size=5,padding='same',strides=1,activation='relu')(x)\n",
        "encoder_out=MaxPool2D()(x)\n",
        "\n",
        "x=UpSampling2D()(encoder_out)\n",
        "x=Conv2D(filters=64,kernel_size=5,padding='same',strides=1,activation='relu')(x)\n",
        "x=UpSampling2D()(x)\n",
        "x=Conv2D(filters=64,kernel_size=5,padding='same',strides=1,activation='relu')(x)\n",
        "x=UpSampling2D()(x)\n",
        "x=Conv2D(filters=128,kernel_size=5,padding='same',strides=1,activation='relu')(x)\n",
        "x=UpSampling2D()(x)\n",
        "decoder_out=Conv2D(filters=3,kernel_size=5,padding='same',strides=1,activation='linear')(x)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_qaqlqT85A7"
      },
      "source": [
        "encoder_model=Model(inputs,encoder_out)\n",
        "auto_model=Model(inputs,decoder_out)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbJ5_-rU-4jb"
      },
      "source": [
        "auto_model.compile(loss='mse',optimizer='adam')\n",
        "auto_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HTbYD_-_Lym"
      },
      "source": [
        "auto_model.fit_generator(train_gen.generator(),steps_per_epoch=np.ceil(all_df.shape[0]/batch_size),epochs=10)\n",
        "auto_model.save('/content/gdrive/My Drive/aptos2019-blindness-detection/auto_model')\n",
        "encoder_model.save('/content/gdrive/My Drive/aptos2019-blindness-detection/encoder_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GAtJXxm_jUz"
      },
      "source": [
        "encoder_model=load_model('/content/gdrive/My Drive/aptos2019-blindness-detection/encoder_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxXgWy8LH99U"
      },
      "source": [
        "### CNN V3 (pretrained + classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-n7gVzjIUf2"
      },
      "source": [
        "# extract the trained encoder layers\n",
        "x_model = encoder_model.output\n",
        "x_model = Flatten()(x_model)\n",
        "# connect the encoder with a fully-connected NN for classification\n",
        "x_model = Dense(64, activation='relu')(x_model)\n",
        "x_model = Dense(32, activation='relu')(x_model)\n",
        "predictions = Dense(5, activation='softmax', name='output_layer')(x_model)\n",
        "model_v3 = Model(inputs=encoder_model.input, outputs=predictions)\n",
        "\n",
        "model_v3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmEU96VRIiH4"
      },
      "source": [
        "epochs=10\n",
        "batch_size=128\n",
        "\n",
        "filepath = '/content/gdrive/My Drive/aptos2019-blindness-detection/model_v3'\n",
        "check = ModelCheckpoint(filepath=filepath,monitor='val_mae',save_best_only=True,save_weights_only=False,mode='min')\n",
        "\n",
        "lrsched = OneCycleScheduler(lr_max=1e-3, n_data_points=train.shape[0],\n",
        "        epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "model_v3.compile(loss=smooth_L1_loss,\n",
        "              optimizer=Adam(lr=1e-3,decay=3e-4), metrics=['mae'])\n",
        "model_v3.fit_generator(train_images,steps_per_epoch=ceil(train.shape[0]/batch_size),\n",
        "                    validation_data=val_images,validation_steps=ceil(val.shape[0]/32),\n",
        "                    epochs=epochs,callbacks=[check,lrsched])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7sBJL3CImnD"
      },
      "source": [
        "# load the model back\n",
        "model_v3 = load_model('/content/gdrive/My Drive/aptos2019-blindness-detection/model_v3',compile=False)\n",
        "model_v3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB2TmJTMI6nV"
      },
      "source": [
        "# generate the predictions on the test set\n",
        "predictions = model_v3.predict_generator(test_images,steps=np.ceil(test.shape[0]/32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkOeRJMCI7qN"
      },
      "source": [
        "# convert the outputs to certain categories\n",
        "pred_labels = predictions.argmax(axis = 1).astype(str)\n",
        "true_labels = test['diagnosis'].to_numpy()\n",
        "\n",
        "# compute performance metrics\n",
        "weighted_f1 = round(f1_score(true_labels, pred_labels, average = 'weighted'), 4)\n",
        "accuracy = round(accuracy_score(true_labels, pred_labels), 4)\n",
        "kappa = round(cohen_kappa_score(true_labels, pred_labels), 4)\n",
        "\n",
        "# display the metrics\n",
        "print(\"Accuracy: {}\".format(accuracy) + '\\n'\n",
        "      + \"Weigjted F1: {}\".format(weighted_f1) + '\\n'\n",
        "      + \"Cohen's Kappa: {}\".format(kappa))\n",
        "\n",
        "# display the confusion matrix\n",
        "confusion_matrix(true_labels, pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_ptjNYYBwHI"
      },
      "source": [
        "### CNN V4 (pretrained + regression)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81nMZZbYAXPT"
      },
      "source": [
        "# extract the trained encoder layers\n",
        "x_model = encoder_model.output\n",
        "x_model = Flatten()(x_model)\n",
        "# connect the encoder with a fully-connected NN for classification\n",
        "x_model = Dense(64, activation='relu')(x_model)\n",
        "x_model = Dense(64, activation='relu')(x_model)\n",
        "predictions = Dense(1, activation='linear', name='output_layer')(x_model)\n",
        "model_v4 = Model(inputs=encoder_model.input, outputs=predictions)\n",
        "\n",
        "model_v4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3D7P_IkBtq7"
      },
      "source": [
        "# train the regression model\n",
        "epochs=10\n",
        "batch_size=128\n",
        "\n",
        "filepath = '/content/gdrive/My Drive/aptos2019-blindness-detection/model_v4'\n",
        "check = ModelCheckpoint(filepath=filepath,monitor='val_mae',save_best_only=True,save_weights_only=False,mode='min')\n",
        "\n",
        "lrsched = OneCycleScheduler(lr_max=1e-3, n_data_points=train.shape[0],\n",
        "        epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "model_v4.compile(loss=smooth_L1_loss,\n",
        "              optimizer=Adam(lr=1e-3,decay=3e-4), metrics=['mae'])\n",
        "model_v4.fit_generator(train_images,steps_per_epoch=ceil(train.shape[0]/batch_size),\n",
        "                    validation_data=val_images,validation_steps=ceil(val.shape[0]/32),\n",
        "                    epochs=epochs,callbacks=[check,lrsched])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1B4T9GlCfih"
      },
      "source": [
        "# load the model back\n",
        "model_v4 = load_model('/content/gdrive/My Drive/aptos2019-blindness-detection/model_v4',compile=False)\n",
        "model_v4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQt_E5i8GkvN"
      },
      "source": [
        "# generate the predictions on the test set\n",
        "predictions = model_v4.predict_generator(test_images,steps=np.ceil(test.shape[0]/32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd7w4CngGsik"
      },
      "source": [
        "true_labels = test['diagnosis'].to_numpy()\n",
        "pre1=predictions*4\n",
        "for i in range(pre1.shape[0]):\n",
        "    if(pre1[i]<=0.5):\n",
        "        pre1[i]=0\n",
        "    elif(pre1[i]>0.5 and pre1[i]<=1.5):\n",
        "        pre1[i]=1\n",
        "    elif(pre1[i]>1.5 and pre1[i]<=2.5):\n",
        "        pre1[i]=2\n",
        "    elif(pre1[i]>2.5 and pre1[i]<=3.5):\n",
        "        pre1[i]=3\n",
        "    else:\n",
        "        pre1[i]=4\n",
        "pred_labels = pre1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6E58HgSG_h7"
      },
      "source": [
        "# compute performance metrics\n",
        "weighted_f1 = round(f1_score(true_labels, pred_labels, average = 'weighted'), 4) # 0.3874\n",
        "accuracy = round(accuracy_score(true_labels, pred_labels), 4) # 0.3753\n",
        "kappa = round(cohen_kappa_score(true_labels, pred_labels), 4) # 0.0183\n",
        "\n",
        "# display the metrics\n",
        "print(\"Accuracy: {}\".format(accuracy) + '\\n'\n",
        "      + \"Weigjted F1: {}\".format(weighted_f1) + '\\n'\n",
        "      + \"Cohen's Kappa: {}\".format(kappa))\n",
        "\n",
        "# display the confusion matrix\n",
        "confusion_matrix(true_labels, pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XZD7Vr2H1xr"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdBgvhjCH5-L"
      },
      "source": [
        "# import the file of labels\n",
        "labels = pd.read_csv('data1/train.csv')\n",
        "# add file type to the column of file names\n",
        "labels['id_code'] = labels['id_code'].astype(str) + '.png'\n",
        "# encode the label column to a categorical variable\n",
        "labels['diagnosis'] = labels['diagnosis']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGHjY1iVIbD1"
      },
      "source": [
        "# import a well-pretrained model with the tops layers unfrozen\n",
        "input_shape=(384,384,3)\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "x_model = base_model.output\n",
        "x_model = GlobalAveragePooling2D(name='globalaveragepooling2d')(x_model)\n",
        "inception_model = Model(inputs=base_model.input, outputs=x_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI_cTu2tImAl"
      },
      "source": [
        "# perform feature extraction to all the images using the pretrained model\n",
        "features=np.zeros((labels.shape[0],2048))\n",
        "batch_size=64\n",
        "def load_image( path, img_size):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    return img/255.0\n",
        "count=0\n",
        "for start in range(0, len(labels), batch_size):\n",
        "    end = min(start + batch_size, len(labels))\n",
        "    df_temp=labels.iloc[start:end]\n",
        "    X=np.zeros((df_temp.shape[0],384,384,3))\n",
        "    for j in range(df_temp.shape[0]):\n",
        "        img=load_image(os.path.join('data1/train_images',df_temp.iloc[j,0]),384)\n",
        "        X[j]=img\n",
        "    pre=inception_model.predict(X)\n",
        "    features[start:end]=pre"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzwjo-w6KCwd"
      },
      "source": [
        "# put the extracted features into the dataframe containing the images paths\n",
        "for i in range(2048):\n",
        "    labels['f_'+str(i)]=0\n",
        "labels.loc[:,'f_0':]=features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx_fMQgCK0Ap"
      },
      "source": [
        "# randomly split the labeled images into a training set and a test set in a ratio of 8:2\n",
        "train_and_val, test = train_test_split(labels, test_size=0.2,random_state=1002965829)\n",
        "# randomly subset 1/10 of the training set to form a validation set\n",
        "train, val = train_test_split(train_and_val, test_size=0.1,random_state=1002965829)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0AFPktwK8YP"
      },
      "source": [
        "K.clear_session()\n",
        "# load the encoder model\n",
        "encoder_model=load_model('/content/gdrive/My Drive/aptos2019-blindness-detection/encoder_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZf1hoYTQGMV"
      },
      "source": [
        "### CNN V5 (pretraining + transfer learning + classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpfgH0VMQPxs"
      },
      "source": [
        "# the first input comes from the enocder model\n",
        "x_model = encoder_model.output\n",
        "x_model = Flatten()(x_model)\n",
        "\n",
        "x_model = Dense(64, activation='relu')(x_model)\n",
        "x_model = Dense(64, activation='relu')(x_model)\n",
        "\n",
        "# the second input comes from the transfer learning\n",
        "inputs1=Input(shape=(2048,))#è¿ç§»æ¨¡åž‹è¾“å‡º\n",
        "x= Dense(64, activation='relu')(inputs1)\n",
        "x_all=concatenate([x_model,x])\n",
        "x_all=Dense(64, activation='relu')(x_all)\n",
        "predictions = Dense(5, activation='softmax', name='output_layer')(x_all)\n",
        "model_v5 = Model(inputs=[encoder_model.input,inputs1], outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP2fD1GuRTDz"
      },
      "source": [
        "filepath =  '/content/gdrive/My Drive/aptos2019-blindness-detection/model_v5'\n",
        "\n",
        "check=ModelCheckpoint(filepath=filepath,monitor='val_acc',save_best_only=True,save_weights_only=False,mode='max')\n",
        "lrsched = OneCycleScheduler(lr_max=1e-3, n_data_points=train.shape[0],\n",
        "        epochs=epochs, batch_size=batch_size, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M47DF1RxRa8i"
      },
      "source": [
        "model_v5.compile(loss=categorical_crossentropy(),\n",
        "              optimizer=Adam(lr=1e-3,decay=3e-4), metrics=['acc'])\n",
        "model_v5.fit_generator(train_imgs,steps_per_epoch=ceil(train.shape[0]/batch_size),validation_data=val_imgs,validation_steps=ceil(val.shape[0]/32),epochs=epochs,callbacks=[check,lrsched])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrPwm-sDRlWa"
      },
      "source": [
        "# generate predicted labels for the test set\n",
        "model_v5 = load_model('/content/gdrive/My Drive/aptos2019-blindness-detection/model_v5',compile=False)\n",
        "model_v5.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASnw6JDaRz77"
      },
      "source": [
        "# convert the outputs to certain categories\n",
        "pred_labels = predictions.argmax(axis = 1).astype(str)\n",
        "true_labels = test['diagnosis'].to_numpy()\n",
        "\n",
        "# compute performance metrics\n",
        "weighted_f1 = round(f1_score(true_labels, pred_labels, average = 'weighted'), 4)\n",
        "accuracy = round(accuracy_score(true_labels, pred_labels), 4)\n",
        "kappa = round(cohen_kappa_score(true_labels, pred_labels), 4)\n",
        "\n",
        "# display the metrics\n",
        "print(\"Accuracy: {}\".format(accuracy) + '\\n'\n",
        "      + \"Weigjted F1: {}\".format(weighted_f1) + '\\n'\n",
        "      + \"Cohen's Kappa: {}\".format(kappa))\n",
        "\n",
        "# display the confusion matrix\n",
        "confusion_matrix(true_labels, pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KF3z3pwPehM"
      },
      "source": [
        "### CNN V6 (pretraining + transfer learning + regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBnpAtbJMmUD"
      },
      "source": [
        "We combine the features that are extracted respectively from the autoencoder and the transfer learning, and use them to train a classification/regression network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxKFj-07LPO8"
      },
      "source": [
        "# the first input comes from the enocder model\n",
        "x_model = encoder_model.output\n",
        "x_model = Flatten()(x_model)\n",
        "\n",
        "x_model = Dense(64, activation='relu')(x_model)\n",
        "x_model = Dense(64, activation='relu')(x_model)\n",
        "\n",
        "# the second input comes from the transfer learning\n",
        "inputs1=Input(shape=(2048,))#è¿ç§»æ¨¡åž‹è¾“å‡º\n",
        "x= Dense(64, activation='relu')(inputs1)\n",
        "x_all=concatenate([x_model,x])\n",
        "x_all=Dense(64, activation='relu')(x_all)\n",
        "predictions = Dense(1, activation='linear', name='output_layer')(x_all)\n",
        "model_v6 = Model(inputs=[encoder_model.input,inputs1], outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJW3D7yqNDmm"
      },
      "source": [
        "filepath =  '/content/gdrive/My Drive/aptos2019-blindness-detection/model_v6'\n",
        "\n",
        "check=ModelCheckpoint(filepath=filepath,monitor='val_mae',save_best_only=True,save_weights_only=False,mode='min')\n",
        "lrsched = OneCycleScheduler(lr_max=1e-3, n_data_points=train.shape[0],\n",
        "        epochs=epochs, batch_size=batch_size, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQmwCYLlNZHi"
      },
      "source": [
        "model_v6.compile(loss=smooth_L1_loss,\n",
        "              optimizer=Adam(lr=1e-3,decay=3e-4), metrics=['mae'])\n",
        "model_v6.fit_generator(train_imgs,steps_per_epoch=ceil(train.shape[0]/batch_size),validation_data=val_imgs,validation_steps=ceil(val.shape[0]/32),epochs=epochs,callbacks=[check,lrsched])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYDI16IbPE3Z"
      },
      "source": [
        "# generate predicted labels for the test set\n",
        "model_v6 = load_model('/content/gdrive/My Drive/aptos2019-blindness-detection/model_v6',compile=False)\n",
        "model_v6.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPAW_qyDPtDC"
      },
      "source": [
        "predictions = model_v6.predict_generator(test_imgs,steps=np.ceil(test.shape[0]/32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Tu_PJOPw4n"
      },
      "source": [
        "true_labels = test['diagnosis'].to_numpy()\n",
        "pre1=predictions*4\n",
        "for i in range(pre1.shape[0]):\n",
        "    if(pre1[i]<=0.5):\n",
        "        pre1[i]=0\n",
        "    elif(pre1[i]>0.5 and pre1[i]<=1.5):\n",
        "        pre1[i]=1\n",
        "    elif(pre1[i]>1.5 and pre1[i]<=2.5):\n",
        "        pre1[i]=2\n",
        "    elif(pre1[i]>2.5 and pre1[i]<=3.5):\n",
        "        pre1[i]=3\n",
        "    else:\n",
        "        pre1[i]=4\n",
        "pred_labels = pre1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5vd1suAP-Dz"
      },
      "source": [
        "# compute performance metrics\n",
        "weighted_f1 = round(f1_score(true_labels, pred_labels, average = 'weighted'), 4) # 0.3874\n",
        "accuracy = round(accuracy_score(true_labels, pred_labels), 4) # 0.3753\n",
        "kappa = round(cohen_kappa_score(true_labels, pred_labels), 4) # 0.0183\n",
        "\n",
        "# display the metrics\n",
        "print(\"Accuracy: {}\".format(accuracy) + '\\n'\n",
        "      + \"Weigjted F1: {}\".format(weighted_f1) + '\\n'\n",
        "      + \"Cohen's Kappa: {}\".format(kappa))\n",
        "\n",
        "# display the confusion matrix\n",
        "confusion_matrix(true_labels, pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}